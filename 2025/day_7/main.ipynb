{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Part 1\n",
    "\n",
    "For part 1, we will keep a list of the indexes of where the beams are located. Then for each of the rows, we will track where these beams go and if they ever hit a splitter or not. We can easily keep a set since there should only be 1 beam per column and some columns may split it up in the same column which meeans they should not be counted as two beams\n"
   ],
   "id": "dcff62bd3b23005"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-04T15:16:33.632138Z",
     "start_time": "2026-01-04T15:16:33.625872Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(\"input.txt\", \"r\") as file:\n",
    "    rows = [list(line.strip()) for line in file.readlines()]\n",
    "\n",
    "beam_indexes = set([i for i, row in enumerate(rows[0]) if row == 'S'])\n",
    "split_count = 0\n",
    "for row in rows[1:]:\n",
    "    for beam_index in beam_indexes.copy():\n",
    "        if row[beam_index] == '^':\n",
    "            split_count += 1\n",
    "            beam_indexes.remove(beam_index)\n",
    "            beam_indexes.add(beam_index + 1)\n",
    "            beam_indexes.add(beam_index - 1)\n",
    "\n",
    "print('Split count:', split_count)"
   ],
   "id": "14fc26c97588e813",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split count: 1594\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Part 2\n",
    "\n",
    "We can now apply some different logic to it. A recursive approach may be best suited here since ti does exactly the thing that is desired. Since we want to see how many different ways we can reach the bottom, a recursive approach will help us explore all the different paths. Or we can simply check that for every splitter we double the number of paths available from a specific point. This means that we can simply keep track of the number of paths available at each beam index and don't have to explore every single path. This does make use of a dictionary to keep track of the number of paths available at each beam index."
   ],
   "id": "b044adb23462b961"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-04T15:16:50.443067Z",
     "start_time": "2026-01-04T15:16:50.437527Z"
    }
   },
   "cell_type": "code",
   "source": [
    "beam_indexes = set([i for i, row in enumerate(rows[0]) if row == 'S'])\n",
    "\n",
    "def count_paths(beam_indexes, rows):\n",
    "    path_counts = {index: 1 for index in beam_indexes}\n",
    "\n",
    "    for row in rows[1:]:\n",
    "        new_path_counts = {}\n",
    "        for beam_index, count in path_counts.items():\n",
    "            if row[beam_index] == '^':\n",
    "                new_path_counts[beam_index - 1] = new_path_counts.get(beam_index - 1, 0) + count\n",
    "                new_path_counts[beam_index + 1] = new_path_counts.get(beam_index + 1, 0) + count\n",
    "            else:\n",
    "                new_path_counts[beam_index] = new_path_counts.get(beam_index, 0) + count\n",
    "        path_counts = new_path_counts\n",
    "\n",
    "    return sum(path_counts.values())\n",
    "\n",
    "print('Unique paths:', count_paths(beam_indexes, rows))"
   ],
   "id": "4a0df4d27b88e29d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique paths: 15650261281478\n"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
